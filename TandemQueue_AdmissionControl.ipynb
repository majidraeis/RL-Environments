{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TandemQueue_AdmissionControl.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMWqm00HnvZd8mpeAtO0GRQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/majidraeis/RL-Environments/blob/master/TandemQueue_AdmissionControl.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fw1TTQhCSIeZ",
        "colab_type": "text"
      },
      "source": [
        "# An Environment for Admission Control in Tandem Queueing Systems \n",
        "<div>\n",
        "<img src=\"https://raw.githubusercontent.com/majidraeis/Figs/master/tandem.png\" width=\"500\"/>\n",
        "</div>\n",
        "\n",
        "## Goal:\n",
        "Consider a tandem multi-server queueing system with $N$ stages. We want to learn an admission control policy that gurantees an upperbound of $d_{ub}$ on the end-to-end delay.\n",
        "\n",
        "## State ($\\bar{s}$):\n",
        "$\\bar{s}=(s_1, s_2, \\cdots, s_N)$\n",
        "\n",
        "i.e., the vector of queue lengths of all the stages upon arrival of a job \n",
        "## Actions ($a$):\n",
        "Accept or Reject the incoming job\n",
        "## Reward ( $R(s,a)$ ):\n",
        ">\n",
        "\n",
        "\\begin{equation*}\n",
        "r = \\left\\{\n",
        "\\begin{array}{ll}\n",
        "+1,  \\qquad & a = Accept,\\qquad d<d_{up}\\\\ \n",
        "-1,  \\qquad & a = Accept,\\qquad d>d_{up}\\\\\n",
        "-1,  \\qquad & a = Reject, \\qquad d<d_{up}\\\\ \n",
        "+1,  \\qquad & a = Reject, \\qquad d>d_{up}\\\\\n",
        "\\end{array} \\right.\n",
        "\\end{equation*}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fd-INWNVIEEx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import copy\n",
        "import random\n",
        "import operator\n",
        "import functools\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import gym\n",
        "from gym  import spaces\n",
        "from tqdm import tqdm\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFYm4nEUaS0S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TandemEnv(gym.Env):\n",
        "\n",
        "    def __init__(self, N_s, Mu_s, rho, d_ub):\n",
        "       \"\"\"\n",
        "       N_s = array of number of servers at each stage\n",
        "       Mu_s = array of service rates \n",
        "       rho = traffic intensity\n",
        "       d_ub = delay upperbound \n",
        "       \"\"\"\n",
        "       self.N_s    = N_s\n",
        "       self.Mu_s   = Mu_s\n",
        "       self.rho    = rho\n",
        "       self.d_ub   = d_ub\n",
        "          \n",
        "       self.job_index  = 1\n",
        "       self.t_arr  = 0\n",
        "       self.cnt    = 1\n",
        "       self.MAX_STEPS = 1000\n",
        "       self.dep_vec = []\n",
        "\n",
        "       B_max = 60      \n",
        "       self.action_space = spaces.Discrete(2)\n",
        "       self.observation_space = [spaces.Discrete(B_max)]*len(N_s)\n",
        "\n",
        "       self.cost = 0\n",
        "       self.opt_flags = {}\n",
        "       self.tandem_job_dict = {}\n",
        "       self.tandem = Tandem(N_s, Mu_s)\n",
        "       self.qls = np.zeros(len(N_s),dtype=int)\n",
        "\n",
        "    def step(self, action, opt_flag):\n",
        "        s = self.qls\n",
        "        index = self.job_index\n",
        "        self._take_action(action)\n",
        "        s_prime = self.qls\n",
        "        reward_vec = []\n",
        "        delay_vec = []\n",
        "        if not action:\n",
        "          virtual_Qnet = copy.deepcopy(self.tandem)\n",
        "          v_flag = True\n",
        "          time = np.copy(self.t_arr)\n",
        "          info_vec = np.zeros((2,3))\n",
        "          info_vec[0] = [index, time, 1]\n",
        "          time += 5\n",
        "          info_vec[1] = [0, time, 0]\n",
        "\n",
        "          while(v_flag):\n",
        "            _, dep_vec = virtual_Qnet._step(info_vec)\n",
        "            departed_indices = dep_vec[:,0]\n",
        "            if index in departed_indices:\n",
        "              v_flag = False\n",
        "              v_delay = 0\n",
        "              for n_s in range(len(self.N_s)):\n",
        "                v_delay += virtual_Qnet.queue[n_s].job_dict[index]['Tw']   \n",
        "              v_delay += virtual_Qnet.queue[n_s].job_dict[index]['Ts'] \n",
        "\n",
        "            info_vec[0] = [0, time, 0]\n",
        "            time += 5\n",
        "            info_vec[1] = [0, time, 0]\n",
        "\n",
        "          del(virtual_Qnet)\n",
        "          reward = self._get_reward(v_delay, action) \n",
        "          reward_vec.append([s, action, s_prime, reward, opt_flag])\n",
        "          if v_delay < self.d_ub: \n",
        "            self.cost += 1\n",
        "        else:\n",
        "          self.tandem_job_dict[index] = {}\n",
        "          self.tandem_job_dict[index]['s'] = s\n",
        "          self.tandem_job_dict[index]['s_prime'] = s_prime\n",
        "          self.opt_flags[index] = opt_flag\n",
        "\n",
        "        for j in range(0, self.dep_vec.shape[0]-1):\n",
        "          index = int(self.dep_vec[j][0])\n",
        "          delay = 0\n",
        "          for n_s in range(len(self.N_s)):\n",
        "            assert(not np.isnan(self.tandem.queue[n_s].job_dict[index]['Tw'])), 'Nan error'\n",
        "            delay += self.tandem.queue[n_s].job_dict[index]['Tw']   \n",
        "          delay += self.tandem.queue[n_s].job_dict[index]['Ts'] \n",
        "          for n_s in range(len(self.N_s)):\n",
        "            del(self.tandem.queue[n_s].job_dict[index])\n",
        "\n",
        "          s = self.tandem_job_dict[index]['s']\n",
        "          s_prime = self.tandem_job_dict[index]['s_prime']\n",
        "          reward = self._get_reward(delay, action)       \n",
        "          reward_vec.append([s, 1, s_prime, reward, self.opt_flags[index]]) #delayed reward, action =1\n",
        "          delay_vec.append(delay)\n",
        "  \n",
        "        done = False if self.cnt < self.MAX_STEPS else True\n",
        "        self.cnt += 1\n",
        "        return self.qls, reward_vec, done, delay_vec\n",
        "\n",
        "    def _take_action(self, action):\n",
        "        info_vec = np.zeros((2,3))\n",
        "        info_vec[0] = [self.job_index, self.t_arr, action]\n",
        "        self.job_index += 1\n",
        "        self.t_arr = self.t_arr + self._inter_arr_gen()\n",
        "        info_vec[1] = [self.job_index, self.t_arr, 0]\n",
        "        self.qls, self.dep_vec = self.tandem._step(info_vec)\n",
        "\n",
        "    def _get_reward(self, delay, action):\n",
        "\n",
        "        if action:\n",
        "          r = 1 if delay <= self.d_ub else -1\n",
        "        else:\n",
        "          r = -1 if delay <= self.d_ub else 1\n",
        "        return r\n",
        "\n",
        "    def _inter_arr_gen(self):\n",
        "        c_a2 = 0.7 #SCV^2\n",
        "        lambda_a = self.N_s[0] * self.rho * self.Mu_s[0]\n",
        "        mean = 1/lambda_a\n",
        "        k = 1/c_a2\n",
        "        theta = mean/k\n",
        "        interTa = np.random.gamma(k, theta)\n",
        "        return interTa\n",
        "    \n",
        "    def reset(self):\n",
        "\n",
        "        self.t_arr = 0\n",
        "        self.job_index = 1\n",
        "        self.cnt = 1\n",
        "        self.qls = np.zeros(len(self.N_s), dtype=int)\n",
        "        self.dep_vec = []\n",
        "        self.tandem_job_dict = {}\n",
        "        self.opt_flags = {}\n",
        "        self.tandem = Tandem(self.N_s, self.Mu_s)\n",
        "        self.cost = 0\n",
        "        return self.qls\n",
        "\n",
        "\"----------Defining constituent queueing elements of the network---------------\"  \n",
        "\n",
        "class Tandem():\n",
        "    def __init__(self, N_s, Mu_s):\n",
        "\n",
        "        self.N_s = N_s\n",
        "        self.Mu_s = Mu_s\n",
        "        self.queue = []\n",
        "        self.ql = np.zeros(len(N_s), dtype=int)\n",
        "        for i,n_s in enumerate(self.N_s):\n",
        "          self.queue.append(Queue(n_s, self.Mu_s[i]))\n",
        "\n",
        "    def _step(self, info_vec):\n",
        "        info_vec_new = np.copy(info_vec)\n",
        "        for i in range(len(self.N_s)):\n",
        "          self.ql[i], departure_vec = self.queue[i]._progress(info_vec_new) \n",
        "          if np.shape(departure_vec)[0]>1:\n",
        "            ind_sorted = np.argsort(departure_vec[:,1])\n",
        "            departure_vec = departure_vec[ind_sorted] \n",
        "          info_vec_new = np.append(departure_vec,info_vec[-1]).reshape(-1, 3)\n",
        "        return self.ql, info_vec_new\n",
        "\n",
        "\n",
        "class Queue():\n",
        "    def __init__(self, n_s, mu_s):\n",
        "        self.n_servers = n_s\n",
        "        self.n_jobs = 0\n",
        "        self.ql_vec = [0]\n",
        "        self.empty_servers = np.arange(n_s)\n",
        "        self.assigned_servers = []\n",
        "        self.t_fin = []\n",
        "        self.ind_fin = []\n",
        "        self.job_dict = {}\n",
        "        self.job_dict[0] = {'Tw': 0.0, 'Ts':0.0}\n",
        "        self.mu_s = mu_s\n",
        "    def _progress(self, info_vec):\n",
        "        departure_vec = []\n",
        "        assert(np.shape(info_vec)[0]>=1), 'error'\n",
        "        for j in range(np.shape(info_vec)[0]-1):\n",
        "          job_index = int(info_vec[j][0])\n",
        "          time = info_vec[j][1]\n",
        "          isArrival = info_vec[j][2]\n",
        "          self.ql = max(self.n_jobs - self.n_servers, 0) # ---before arrival----\n",
        "          if isArrival:\n",
        "              if self.n_jobs < self.n_servers:\n",
        "                  t_ent = time\n",
        "                  self.empty_servers = [x for x in range(self.n_servers) if x not in self.assigned_servers]\n",
        "                  self.assigned_servers = np.append(self.assigned_servers, random.choice(self.empty_servers))\n",
        "\n",
        "              else:\n",
        "                  # ------finding the time that each server gets empty----------\n",
        "                  t_available = [np.max(self.t_fin[self.assigned_servers == i]) for i in range(self.n_servers)]\n",
        "                  # ----------pick the earliest server available----------------\n",
        "                  picked_server = np.argmin(t_available)\n",
        "                  t_ent = max(time, t_available[picked_server])\n",
        "                  self.assigned_servers = np.append(self.assigned_servers, picked_server)\n",
        "\n",
        "              t_s = self._service_gen()\n",
        "              self.t_fin = np.append(self.t_fin, t_ent + t_s)\n",
        "              self.ind_fin = np.append(self.ind_fin, job_index)\n",
        "              self.n_jobs += 1\n",
        "              self.job_dict[job_index] = {'Ta': time, 'Td': t_ent + t_s, 'Ts': t_s, 'Tw': t_ent- time,\n",
        "                                              'Ba': self.ql}\n",
        "\n",
        "          next_time = info_vec[j+1][1]\n",
        "          self.n_jobs -= np.sum(np.array(self.t_fin) < next_time)\n",
        "          served_jobs = np.arange(len(self.t_fin))[np.array(self.t_fin) < next_time]\n",
        "          for i in served_jobs:\n",
        "            departure_vec.append([int(self.ind_fin[i]), self.t_fin[i], 1])\n",
        "          self.t_fin = np.delete(self.t_fin, served_jobs)\n",
        "          self.ind_fin = np.delete(self.ind_fin, served_jobs)\n",
        "          self.assigned_servers = np.delete(self.assigned_servers, served_jobs)\n",
        "\n",
        "        if np.shape(info_vec)[0]==1:\n",
        "          next_time = info_vec[0][1]\n",
        "          self.n_jobs -= np.sum(np.array(self.t_fin) < next_time)\n",
        "          served_jobs = np.arange(len(self.t_fin))[np.array(self.t_fin) < next_time]\n",
        "          for i in served_jobs:\n",
        "            departure_vec.append([int(self.ind_fin[i]), self.t_fin[i], 1])\n",
        "          self.t_fin = np.delete(self.t_fin, served_jobs)\n",
        "          self.ind_fin = np.delete(self.ind_fin, served_jobs)\n",
        "          self.assigned_servers = np.delete(self.assigned_servers, served_jobs)\n",
        "        # ----queue length of this stage before the next arrival to the first stage----\n",
        "        QL = max(self.n_jobs - self.n_servers, 0) \n",
        "        return QL, np.array(departure_vec)\n",
        "\n",
        "    def _service_gen(self):\n",
        "        #-----Gamma Distributed Service times----\n",
        "        c_s2 = 0.8 #--SCV^2--\n",
        "        mean = 1/self.mu_s\n",
        "        k = 1/c_s2\n",
        "        theta = mean/k\n",
        "        Ts = np.random.gamma(k, theta)\n",
        "        return Ts"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}